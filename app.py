import streamlit as st
import google.generativeai as genai
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ’’ ì›¨ë”© ì˜ˆì‹ ì±—ë´‡",
    page_icon="ğŸ’’",
)

# ì œëª© í‘œì‹œ
st.title("ğŸ’’ ì›¨ë”© ì˜ˆì‹ ì±—ë´‡")

# í•˜ë“œì½”ë”©ëœ ì‘ë‹µ ì •ì˜
PREDEFINED_RESPONSES = {
    "parking": "ì˜ˆì‹ì¥ ì§€í•˜ 1ì¸µ ì „ìš© ì£¼ì°¨ì¥ì„ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ë£Œë¡œ ì œê³µë©ë‹ˆë‹¤.",
    "location": "ì˜ˆì‹ì¥ì€ ì„œìš¸ ê°•ë‚¨êµ¬ ì²­ë‹´ë™ì— ìœ„ì¹˜í•œ ì²­ë‹´ì›¨ë”©í™€ 3ì¸µì…ë‹ˆë‹¤.",
    "time": "ì˜ˆì‹ì€ 2025ë…„ 10ì›” 25ì¼ í† ìš”ì¼ ì˜¤í›„ 2ì‹œì— ì‹œì‘ë©ë‹ˆë‹¤."
}

# ì§ˆë¬¸ íŒ¨í„´ ì •ì˜
QUESTION_PATTERNS = {
    "parking": r"ì£¼ì°¨.*(ì–´ë””|ìœ„ì¹˜|ê°€ëŠ¥|ë˜ë‚˜)",
    "location": r"(ì˜ˆì‹ì¥|ì›¨ë”©í™€|ì¥ì†Œ).*(ì–´ë””|ìœ„ì¹˜|ì£¼ì†Œ)",
    "time": r"(ì˜ˆì‹|ê²°í˜¼).*(ì‹œê°„|ì–¸ì œ)"
}

def get_predefined_response(question):
    """ì‚¬ì „ ì •ì˜ëœ ì§ˆë¬¸ì¸ì§€ í™•ì¸í•˜ê³  í•´ë‹¹í•˜ëŠ” ì‘ë‹µì„ ë°˜í™˜"""
    question = question.strip()
    
    for key, pattern in QUESTION_PATTERNS.items():
        if re.search(pattern, question):
            return PREDEFINED_RESPONSES[key]
    
    return None

# Gemini API ì„¤ì •
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# ì±„íŒ… ê¸°ë¡ì„ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    # Gemini ì±„íŒ… ì„¸ì…˜ ì´ˆê¸°í™”
    st.session_state.chat = model.start_chat(history=[])

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    try:
        # ì‚¬ì „ ì •ì˜ëœ ì‘ë‹µ í™•ì¸
        predefined_response = get_predefined_response(prompt)
        
        if predefined_response:
            # í•˜ë“œì½”ë”©ëœ ì‘ë‹µ ì‚¬ìš©
            response_text = predefined_response
        else:
            # Gemini APIë¡œ ì‘ë‹µ ìƒì„±
            response = st.session_state.chat.send_message(prompt)
            response_text = response.text
            
            # ì˜ˆì‹ ì •ë³´ ì™¸ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ ë³€ê²½
            if "ì£„ì†¡í•©ë‹ˆë‹¤" in response_text or "ë‹µë³€ë“œë¦¬ê¸° ì–´ë µ" in response_text:
                response_text = "ì£„ì†¡í•©ë‹ˆë‹¤, ì˜ˆì‹ ì •ë³´ ì™¸ì˜ ë‹µë³€ì€ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì±—ë´‡ ì‘ë‹µ í‘œì‹œ
        with st.chat_message("assistant"):
            st.markdown(response_text)
        
        # ì±—ë´‡ ì‘ë‹µì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
        st.session_state.chat_history.append({"role": "assistant", "content": response_text})
            
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
